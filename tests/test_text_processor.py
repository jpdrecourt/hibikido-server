"""
Test Hierarchical Text Processor
================================

Test the updated text processor with hierarchical context.
"""

import tempfile
import shutil
from hibikido.database_manager import HibikidoDatabase
from hibikido.embedding_manager import EmbeddingManager
from hibikido.text_processor import TextProcessor

def test_hierarchical_text_processing():
    """Test hierarchical text processing for segments and presets."""
    print("üß™ Testing Hierarchical Text Processing")
    print("=" * 50)
    
    # Setup
    temp_dir = tempfile.mkdtemp()
    
    try:
        # Initialize components
        db = HibikidoDatabase(db_name="hibikido_text_test")
        if not db.connect():
            print("‚ùå Failed to connect to MongoDB")
            return False
        
        text_processor = TextProcessor()
        print("‚úÖ Text processor initialized")
        
        em = EmbeddingManager(index_file=f"{temp_dir}/text_test.index")
        if not em.initialize():
            print("‚ùå Failed to initialize embedding manager")
            return False
        
        # Create rich test data
        print("\nüìù Creating rich test data...")
        
        # Add recording with detailed description
        recording_desc = "Dawn chorus recorded in ancient oak woodland during spring migration, misty morning with gentle breeze rustling leaves"
        db.add_recording("forest_dawn_rich", "recordings/forest_dawn_detailed.wav", recording_desc)
        
        # Add segmentation with method description
        segmentation_desc = "Hand-segmented individual bird vocalizations using spectral analysis to isolate territorial calls and songs"
        db.add_segmentation("manual_bird_analysis", "manual", 
                          {"tool": "spectral_analysis", "focus": "territorial_calls"}, 
                          segmentation_desc)
        
        # Add segments with varying description richness
        segments_data = [
            {
                "id": "robin_territorial_detailed",
                "description": "Male robin territorial call with characteristic rising pitch pattern, assertive and bright timbre"
            },
            {
                "id": "blackbird_minimal", 
                "description": "Blackbird song"  # Minimal description
            },
            {
                "id": "thrush_medium",
                "description": "Song thrush melodic phrase with repeated motifs"  # Medium description
            }
        ]
        
        for seg_data in segments_data:
            db.add_segment(
                segment_id=seg_data["id"],
                source_id="forest_dawn_rich",
                segmentation_id="manual_bird_analysis",
                start=0.0, end=1.0,
                description=seg_data["description"],
                embedding_text=""  # Will be generated by text processor
            )
        
        # Add effect with detailed description
        effect_desc = "Advanced granular synthesis processor with independent control over grain size, pitch variation, temporal stretching and spatial distribution"
        db.add_effect("granular_advanced", "Advanced Granular Processor", 
                     "/effects/granular_advanced.maxpat", effect_desc)
        
        # Add presets with varying description quality
        presets_data = [
            {
                "parameters": [
                    {"name": "grain_size", "value": 0.05},
                    {"name": "pitch_variation", "value": 0.2}
                ],
                "description": "Ethereal atmospheric texture with subtle pitch modulation and extended temporal stretching creating dreamlike soundscape",
                "embedding_text": ""
            },
            {
                "parameters": [
                    {"name": "grain_size", "value": 0.01},
                    {"name": "pitch_variation", "value": 1.5}
                ],
                "description": "Glitchy effect",  # Minimal description
                "embedding_text": ""
            }
        ]
        
        for preset in presets_data:
            db.add_preset_to_effect("granular_advanced", preset)
        
        print("‚úÖ Rich test data created")
        
        # Test hierarchical text processing
        print("\nüîç Testing hierarchical context...")
        
        # Get the data for testing
        recording = db.get_recording("forest_dawn_rich")
        segmentation = db.get_segmentation("manual_bird_analysis")
        effect = db.get_effect("granular_advanced")
        
        # Test segment text processing
        print("\nüìÑ Segment Text Processing:")
        segments = db.get_segments_by_recording("forest_dawn_rich")
        
        for segment in segments:
            # Create hierarchical embedding text
            embedding_text = text_processor.create_segment_embedding_text(
                segment, recording, segmentation
            )
            
            print(f"\n  Segment: {segment['_id']}")
            print(f"    Original: '{segment['description']}'")
            print(f"    Enhanced: '{embedding_text}'")
            print(f"    Words: {len(embedding_text.split())}")
            
            # Verify word count
            word_count = len(embedding_text.split())
            if word_count > 20:
                print(f"    ‚ùå Too many words: {word_count} > 20")
                return False
            elif word_count < 5:
                print(f"    ‚ö†Ô∏è  Very few words: {word_count}")
            else:
                print(f"    ‚úÖ Good word count: {word_count}")
        
        # Test preset text processing
        print("\nüéõÔ∏è  Preset Text Processing:")
        
        for i, preset in enumerate(effect.get("presets", [])):
            # Create hierarchical embedding text
            embedding_text = text_processor.create_preset_embedding_text(preset, effect)
            
            print(f"\n  Preset {i+1}:")
            print(f"    Original: '{preset['description']}'")
            print(f"    Enhanced: '{embedding_text}'")
            print(f"    Words: {len(embedding_text.split())}")
            
            # Verify word count
            word_count = len(embedding_text.split())
            if word_count > 20:
                print(f"    ‚ùå Too many words: {word_count} > 20")
                return False
            elif word_count < 3:
                print(f"    ‚ö†Ô∏è  Very few words: {word_count}")
            else:
                print(f"    ‚úÖ Good word count: {word_count}")
        
        # Test full rebuild with hierarchical context
        print("\nüîÑ Testing full rebuild with hierarchical context...")
        
        stats = em.rebuild_from_database(db, text_processor)
        
        print(f"üìä Rebuild stats: {stats}")
        
        if stats["segments_added"] == 3 and stats["presets_added"] == 2:
            print("‚úÖ All items processed successfully")
        else:
            print(f"‚ùå Expected 3 segments and 2 presets, got {stats['segments_added']} segments and {stats['presets_added']} presets")
            return False
        
        # Test search with enhanced embeddings
        print("\nüîç Testing search with enhanced embeddings...")
        
        test_queries = [
            {
                "query": "territorial bird call morning",
                "expected": "robin_territorial_detailed"
            },
            {
                "query": "ethereal atmospheric granular",
                "expected": "preset"
            },
            {
                "query": "oak woodland spring migration",
                "expected": "forest context"
            }
        ]
        
        for test in test_queries:
            results = em.search(test["query"], top_k=3, db_manager=db)
            
            print(f"\n  Query: '{test['query']}'")
            if results:
                print(f"    Top result: {results[0]['collection']} - score: {results[0]['score']:.3f}")
                
                # Show the enhanced embedding text that was matched
                doc = results[0]['document']
                if results[0]['collection'] == 'segments':
                    enhanced_text = doc.get('embedding_text', 'no embedding text')
                    print(f"    Enhanced text: '{enhanced_text}'")
                elif results[0]['collection'] == 'presets':
                    enhanced_text = doc.get('embedding_text', 'no embedding text')
                    print(f"    Enhanced text: '{enhanced_text}'")
                
                print("    ‚úÖ Search working")
            else:
                print("    ‚ùå No results found")
                return False
        
        # Test spaCy vs simple processing comparison
        print("\nüî¨ Testing text processing methods...")
        
        test_text = "The beautiful birds are singing melodically in the morning forest with gentle atmospheric reverb effects"
        
        # Test keyword extraction
        keywords_simple = text_processor._extract_keywords_simple(test_text, max_words=15)
        print(f"\n  Simple processing: {' '.join(keywords_simple)} ({len(keywords_simple)} words)")
        
        if text_processor.nlp:
            keywords_spacy = text_processor._extract_keywords_spacy(test_text, max_words=15)
            print(f"  spaCy processing: {' '.join(keywords_spacy)} ({len(keywords_spacy)} words)")
        else:
            print("  spaCy not available")
        
        print("\nüéâ All hierarchical text processing tests passed!")
        return True
        
    except Exception as e:
        print(f"‚ùå Test failed with exception: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # Cleanup
        try:
            db.client.drop_database("hibikido_text_test")
            db.close()
        except:
            pass
        
        shutil.rmtree(temp_dir, ignore_errors=True)
        print("üßπ Cleaned up test data")

if __name__ == "__main__":
    print("üöÄ Running Hierarchical Text Processor Tests")
    print("=" * 60)
    
    success = test_hierarchical_text_processing()
    
    print(f"\n{'='*60}")
    print("üìä TEST SUMMARY")
    print(f"{'='*60}")
    
    if success:
        print("‚úÖ PASS Hierarchical Text Processing")
        print("\nüéâ All tests passed!")
        print("\nKey improvements:")
        print("- Hierarchical context: segment > segmentation > recording")
        print("- Smart word limits: ~15 words, max 20")
        print("- spaCy integration for better keyword extraction")
        print("- Priority-based text combination")
        print("- Enhanced embedding quality for search")
    else:
        print("‚ùå FAIL Hierarchical Text Processing")
        print("\n‚ö†Ô∏è  Tests failed - check output above")
    
    exit(0 if success else 1)