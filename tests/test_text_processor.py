"""
Test Hierarchical Text Processor (Updated for Path-based Schema)
================================================================

Test the updated text processor with hierarchical context using path-based references.
"""

import tempfile
import shutil
from hibikido.database_manager import HibikidoDatabase
from hibikido.embedding_manager import EmbeddingManager
from hibikido.text_processor import TextProcessor

def test_hierarchical_text_processing():
    """Test hierarchical text processing for segments and presets with path-based schema."""
    print("🧪 Testing Hierarchical Text Processing (Path-based)")
    print("=" * 60)
    
    # Setup
    temp_dir = tempfile.mkdtemp()
    
    try:
        # Initialize components
        db = HibikidoDatabase(db_name="hibikido_text_test")
        if not db.connect():
            print("❌ Failed to connect to MongoDB")
            assert False
        
        text_processor = TextProcessor()
        print("✅ Text processor initialized")
        
        em = EmbeddingManager(index_file=f"{temp_dir}/text_test.index")
        if not em.initialize():
            print("❌ Failed to initialize embedding manager")
            assert False
        
        # Create rich test data using path-based schema
        print("\n📝 Creating rich test data...")
        
        # Add recordings with detailed descriptions (path-based)
        recordings = [
            {
                "path": "recordings/nature/forest_dawn_detailed.wav",
                "description": "Dawn chorus recorded in ancient oak woodland during spring migration, misty morning with gentle breeze rustling leaves"
            },
            {
                "path": "recordings/urban/city_evening.wav", 
                "description": "Urban evening ambience with distant traffic, occasional footsteps, and muffled conversations"
            }
        ]
        
        for rec in recordings:
            db.add_recording(rec["path"], rec["description"])
        
        # Add segmentation with method description
        segmentation_desc = "Hand-segmented individual bird vocalizations using spectral analysis to isolate territorial calls and songs"
        db.add_segmentation("manual_bird_analysis", "manual", 
                          {"tool": "spectral_analysis", "focus": "territorial_calls"}, 
                          segmentation_desc)
        
        # Add segments with varying description richness (using path references and normalized values)
        segments_data = [
            {
                "source_path": "recordings/nature/forest_dawn_detailed.wav",
                "start": 0.05, "end": 0.35,  # Normalized values
                "description": "Male robin territorial call with characteristic rising pitch pattern, assertive and bright timbre"
            },
            {
                "source_path": "recordings/nature/forest_dawn_detailed.wav",
                "start": 0.4, "end": 0.8,
                "description": "Blackbird song"  # Minimal description
            },
            {
                "source_path": "recordings/nature/forest_dawn_detailed.wav",
                "start": 0.85, "end": 1.0,
                "description": "Song thrush melodic phrase with repeated motifs"  # Medium description
            }
        ]
        
        for seg_data in segments_data:
            success = db.add_segment(
                source_path=seg_data["source_path"],
                segmentation_id="manual_bird_analysis",
                start=seg_data["start"],
                end=seg_data["end"],
                description=seg_data["description"],
                embedding_text=""  # Will be generated by text processor
            )
            assert success, f"Failed to add segment: {seg_data['description']}"
        
        # Add effects with detailed descriptions (path-based)
        effects = [
            {
                "path": "effects/granular/advanced_processor.maxpat",
                "name": "Advanced Granular Processor",
                "description": "Advanced granular synthesis processor with independent control over grain size, pitch variation, temporal stretching and spatial distribution"
            },
            {
                "path": "effects/reverb/convolution_hall.maxpat",
                "name": "Convolution Hall",
                "description": "High-quality convolution reverb simulating concert hall acoustics"
            }
        ]
        
        for fx in effects:
            db.add_effect(fx["path"], fx["name"], fx["description"])
        
        # Add presets with varying description quality (separate collection)
        presets_data = [
            {
                "effect_path": "effects/granular/advanced_processor.maxpat",
                "parameters": [0.05, 0.2, 2.0, 0.7],
                "description": "Ethereal atmospheric texture with subtle pitch modulation and extended temporal stretching creating dreamlike soundscape"
            },
            {
                "effect_path": "effects/granular/advanced_processor.maxpat",
                "parameters": [0.01, 1.5, 0.5, 0.9],
                "description": "Glitchy effect"  # Minimal description
            },
            {
                "effect_path": "effects/reverb/convolution_hall.maxpat",
                "parameters": [0.6, 0.3, 0.8],
                "description": "Warm concert hall ambience with natural decay"
            }
        ]
        
        for preset in presets_data:
            success = db.add_preset(
                effect_path=preset["effect_path"],
                parameters=preset["parameters"],
                description=preset["description"],
                embedding_text=""  # Will be generated
            )
            assert success, f"Failed to add preset: {preset['description']}"
        
        print("✅ Rich test data created with path-based references")
        
        # Test hierarchical text processing
        print("\n🔍 Testing hierarchical context generation...")
        
        # Get the data for testing (path-based lookups)
        forest_recording = db.get_recording_by_path("recordings/nature/forest_dawn_detailed.wav")
        segmentation = db.get_segmentation("manual_bird_analysis")
        granular_effect = db.get_effect_by_path("effects/granular/advanced_processor.maxpat")
        
        # Test segment text processing
        print("\n📄 Segment Text Processing:")
        segments = db.get_segments_by_recording_path("recordings/nature/forest_dawn_detailed.wav")
        
        for segment in segments:
            # Create hierarchical embedding text
            embedding_text = text_processor.create_segment_embedding_text(
                segment, forest_recording, segmentation
            )
            
            print(f"\n  Segment: {str(segment['_id'])}")
            print(f"    Source: {segment['source_path']}")
            print(f"    Timing: [{segment['start']:.1f}-{segment['end']:.1f}] (normalized)")
            print(f"    Original: '{segment['description']}'")
            print(f"    Enhanced: '{embedding_text}'")
            print(f"    Words: {len(embedding_text.split())}")
            
            # Verify word count
            word_count = len(embedding_text.split())
            if word_count > 20:
                print(f"    ❌ Too many words: {word_count} > 20")
                assert False
            elif word_count < 5:
                print(f"    ⚠️  Very few words: {word_count}")
            else:
                print(f"    ✅ Good word count: {word_count}")
            
            # Verify normalized timing
            start = segment.get("start", -1)
            end = segment.get("end", -1)
            if not (0.0 <= start <= 1.0 and 0.0 <= end <= 1.0 and start < end):
                print(f"    ❌ Invalid normalized timing: {start}-{end}")
                assert False
        
        # Test preset text processing (separate collection)
        print("\n🎛️  Preset Text Processing:")
        
        granular_presets = db.get_presets_by_effect_path("effects/granular/advanced_processor.maxpat")
        reverb_presets = db.get_presets_by_effect_path("effects/reverb/convolution_hall.maxpat")
        all_presets = granular_presets + reverb_presets
        
        for i, preset in enumerate(all_presets):
            # Get effect for hierarchical context (path-based lookup)
            effect = db.get_effect_by_path(preset["effect_path"])
            
            # Create hierarchical embedding text
            embedding_text = text_processor.create_preset_embedding_text(preset, effect)
            
            print(f"\n  Preset {i+1}:")
            print(f"    Effect: {preset['effect_path']}")
            print(f"    Parameters: {preset['parameters']}")
            print(f"    Original: '{preset['description']}'")
            print(f"    Enhanced: '{embedding_text}'")
            print(f"    Words: {len(embedding_text.split())}")
            
            # Verify word count
            word_count = len(embedding_text.split())
            if word_count > 20:
                print(f"    ❌ Too many words: {word_count} > 20")
                assert False
            elif word_count < 3:
                print(f"    ⚠️  Very few words: {word_count}")
            else:
                print(f"    ✅ Good word count: {word_count}")
        
        # Test full rebuild with hierarchical context
        print("\n🔄 Testing full rebuild with hierarchical context...")
        
        stats = em.rebuild_from_database(db, text_processor)
        
        print(f"📊 Rebuild stats: {stats}")
        
        expected_segments = len(segments_data)
        expected_presets = len(presets_data)
        
        if stats["segments_added"] == expected_segments and stats["presets_added"] == expected_presets:
            print("✅ All items processed successfully")
        else:
            print(f"❌ Expected {expected_segments} segments and {expected_presets} presets, got {stats['segments_added']} segments and {stats['presets_added']} presets")
            assert False
        
        # Test search with enhanced embeddings
        print("\n🔍 Testing search with enhanced embeddings...")
        
        test_queries = [
            {
                "query": "territorial bird call morning oak",
                "expected_collection": "segments",
                "expected_path": "recordings/nature/forest_dawn_detailed.wav"
            },
            {
                "query": "ethereal atmospheric granular texture",
                "expected_collection": "presets",
                "expected_path": "effects/granular/advanced_processor.maxpat"
            },
            {
                "query": "concert hall reverb natural decay",
                "expected_collection": "presets", 
                "expected_path": "effects/reverb/convolution_hall.maxpat"
            },
            {
                "query": "spring migration ancient woodland",
                "expected_collection": "segments",  # Should match via recording context
                "expected_path": "recordings/nature/forest_dawn_detailed.wav"
            }
        ]
        
        for test in test_queries:
            results = em.search(test["query"], top_k=3, db_manager=db)
            
            print(f"\n  Query: '{test['query']}'")
            if results:
                top_result = results[0]
                collection = top_result['collection']
                doc = top_result['document']
                score = top_result['score']
                
                if collection == "segments":
                    path = doc.get('source_path', 'unknown')
                    start = doc.get('start', 0.0)
                    end = doc.get('end', 1.0)
                    print(f"    Top result: [segment] {path} [{start:.1f}-{end:.1f}] (score: {score:.3f})")
                else:
                    path = doc.get('effect_path', 'unknown')
                    params = doc.get('parameters', [])
                    print(f"    Top result: [preset] {path} {params} (score: {score:.3f})")
                
                # Show the enhanced embedding text that was matched
                enhanced_text = doc.get('embedding_text', 'no embedding text')
                print(f"    Enhanced text: '{enhanced_text}'")
                
                # Check if result matches expectations
                collection_match = collection == test["expected_collection"]
                path_match = path == test["expected_path"]
                
                if collection_match and path_match:
                    print("    ✅ Expected result found")
                else:
                    print(f"    ⚠️  Different result: expected {test['expected_collection']} from {test['expected_path']}")
                
            else:
                print("    ❌ No results found")
                assert False
        
        # Test path-based context integration
        print("\n🛤️  Testing path-based context integration...")
        
        # Verify segments can access recording context via path
        test_segment = segments[0]  # Robin territorial call
        recording_context = db.get_recording_by_path(test_segment["source_path"])
        
        if recording_context and "oak woodland" in recording_context["description"]:
            print("    ✅ Segments can access recording context via path")
        else:
            print("    ❌ Path-based recording context failed")
            assert False
        
        # Verify presets can access effect context via path  
        test_preset = all_presets[0]  # Ethereal granular texture
        effect_context = db.get_effect_by_path(test_preset["effect_path"])
        
        if effect_context and "granular synthesis" in effect_context["description"]:
            print("    ✅ Presets can access effect context via path")
        else:
            print("    ❌ Path-based effect context failed")
            assert False
        
        # Test spaCy vs simple processing comparison
        print("\n🔬 Testing text processing methods...")
        
        test_text = "The beautiful ethereal birds are singing melodically in the morning forest with gentle atmospheric reverb effects"
        
        # Test keyword extraction
        keywords_simple = text_processor._extract_keywords_simple(test_text, max_words=15)
        print(f"\n  Simple processing: {' '.join(keywords_simple)} ({len(keywords_simple)} words)")
        
        if text_processor.nlp and hasattr(text_processor, 'spacy_working') and text_processor.spacy_working:
            keywords_spacy = text_processor._extract_keywords_spacy(test_text, max_words=15)
            print(f"  spaCy processing: {' '.join(keywords_spacy)} ({len(keywords_spacy)} words)")
            
            # Compare effectiveness
            spacy_has_more_relevant = any(word in keywords_spacy for word in ["ethereal", "melodic", "atmospheric"])
            if spacy_has_more_relevant:
                print("  ✅ spaCy processing shows improved keyword extraction")
            else:
                print("  ⚠️  spaCy processing similar to simple method")
        else:
            print("  ℹ️  spaCy not available or not working")
        
        # Test hierarchical word limit enforcement
        print("\n📏 Testing hierarchical word limits...")
        
        # Create test data with very long descriptions
        long_segment = {
            "description": "This is an extremely long and detailed description of a bird call that contains many many words and should be truncated to fit within the word limits while preserving the most important semantic information",
            "source_path": "recordings/nature/forest_dawn_detailed.wav"
        }
        
        long_recording = {
            "description": "This recording was made in a very specific location with lots of contextual information that might be relevant but should be limited in the final embedding text to maintain focus",
            "path": "recordings/nature/forest_dawn_detailed.wav"
        }
        
        long_segmentation = {
            "description": "Manual segmentation process using advanced spectral analysis tools with specific parameters and methodology details"
        }
        
        # Test word limit enforcement
        embedding_text = text_processor.create_segment_embedding_text(
            long_segment, long_recording, long_segmentation
        )
        
        word_count = len(embedding_text.split())
        print(f"  Long descriptions → {word_count} words: '{embedding_text}'")
        
        if word_count <= 20:
            print("  ✅ Word limits properly enforced")
        else:
            print(f"  ❌ Word limit exceeded: {word_count} > 20")
            assert False
        
        # Test priority ordering (local > method > source)
        if "bird call" in embedding_text and "recording" not in embedding_text:
            print("  ✅ Priority ordering working (local content prioritized)")
        else:
            print("  ⚠️  Priority ordering may need adjustment")
        
        print("\n🎉 All hierarchical text processing tests passed!")
        assert True
        
    except Exception as e:
        print(f"❌ Test failed with exception: {e}")
        import traceback
        traceback.print_exc()
        assert False
    
    finally:
        # Cleanup
        try:
            db.client.drop_database("hibikido_text_test")
            db.close()
        except:
            pass
        
        shutil.rmtree(temp_dir, ignore_errors=True)
        print("🧹 Cleaned up test data")

def test_text_processor_edge_cases():
    """Test edge cases and error handling in text processor."""
    print(f"\n🧪 Testing Text Processor Edge Cases")
    print("=" * 50)
    
    text_processor = TextProcessor()
    
    # Test empty/None inputs using hierarchical method
    print("\n📭 Testing empty inputs...")
    
    empty_tests = [
        {"description": "", "expected_min_words": 1},
        {"description": None, "expected_min_words": 1},
        {"description": "   ", "expected_min_words": 1},
    ]
    
    for test in empty_tests:
        # Use hierarchical method with minimal context
        segment = {"description": test["description"]}
        recording = {"description": "test recording", "path": "test.wav"}
        segmentation = {"description": "test segmentation"}
        
        result = text_processor.create_segment_embedding_text(segment, recording, segmentation)
        
        if len(result.split()) >= test["expected_min_words"]:
            print(f"   ✅ Empty input handled: '{test['description']}' → '{result}'")
        else:
            print(f"   ❌ Empty input failed: '{test['description']}' → '{result}' (expected at least {test['expected_min_words']} words)")
            assert False
    
    # Test very short inputs
    print("\n📝 Testing minimal inputs...")
    
    minimal_segment = {"description": "bird"}
    minimal_recording = {"description": "forest", "path": "test.wav"}
    minimal_segmentation = {"description": "manual"}
    
    result = text_processor.create_segment_embedding_text(
        minimal_segment, minimal_recording, minimal_segmentation
    )
    
    if len(result.split()) >= 2:
        print(f"   ✅ Minimal input expanded: 'bird' → '{result}'")
    else:
        print(f"   ❌ Minimal input not expanded properly: '{result}'")
        assert False
    
    # Test very long inputs
    print("\n📏 Testing oversized inputs...")
    
    oversized_description = " ".join([f"word{i}" for i in range(50)])  # 50 words
    oversized_segment = {"description": oversized_description}
    oversized_recording = {"description": oversized_description, "path": "test.wav"}
    oversized_segmentation = {"description": oversized_description}
    
    result = text_processor.create_segment_embedding_text(
        oversized_segment, oversized_recording, oversized_segmentation
    )
    
    word_count = len(result.split())
    if word_count <= 20:
        print(f"   ✅ Oversized input truncated: {word_count} words")
    else:
        print(f"   ❌ Oversized input not truncated: {word_count} words")
        assert False
    
    # Test special characters and unicode
    print("\n🔤 Testing special characters...")
    
    special_tests = [
        "Bird call with émphasis ànd spëcial chars",
        "Sound with numbers 123 and symbols @#$%",
        "Mixed_case-SOUND with.punctuation!",
        "Très très spécial français texte"
    ]
    
    for test_text in special_tests:
        segment = {"description": test_text}
        recording = {"description": "test recording", "path": "test.wav"}
        segmentation = {"description": "test segmentation"}
        
        result = text_processor.create_segment_embedding_text(segment, recording, segmentation)
        
        # Should produce some meaningful output
        if len(result) > 0 and len(result.split()) >= 2:
            print(f"   ✅ Special chars handled: '{test_text}' → '{result}'")
        else:
            print(f"   ❌ Special chars failed: '{test_text}' → '{result}'")
            assert False
    
    # Test preset edge cases too
    print("\n🎛️  Testing preset edge cases...")
    
    empty_preset = {"description": "", "parameters": []}
    test_effect = {"description": "test effect", "name": "Test", "path": "test.maxpat"}
    
    result = text_processor.create_preset_embedding_text(empty_preset, test_effect)
    
    if len(result.split()) >= 1:
        print(f"   ✅ Empty preset handled: '' → '{result}'")
    else:
        print(f"   ❌ Empty preset failed: '' → '{result}'")
        assert False
    
    print("\n✅ All edge case tests passed!")
    # Don't return True/False, just pass or assert

if __name__ == "__main__":
    print("🚀 Running Path-based Hierarchical Text Processor Tests")
    print("=" * 70)
    
    # Test 1: Main hierarchical processing
    success1 = test_hierarchical_text_processing()
    
    # Test 2: Edge cases and error handling
    success2 = test_text_processor_edge_cases()
    
    print(f"\n{'='*70}")
    print("📊 TEST SUMMARY")
    print(f"{'='*70}")
    
    tests = [
        ("Hierarchical Text Processing", success1),
        ("Text Processor Edge Cases", success2)
    ]
    
    passed = sum(1 for _, result in tests if result)
    total = len(tests)
    
    for test_name, result in tests:
        status = "✅ PASS" if result else "❌ FAIL"
        print(f"{status} {test_name}")
    
    print(f"\n🎯 Overall: {passed}/{total} tests passed ({passed/total:.1%})")
    
    if passed == total:
        print("\n🎉 All tests passed!")
        print("\nKey improvements verified:")
        print("- Path-based hierarchical context: segment > segmentation > recording")
        print("- Separate presets collection with effect_path references")
        print("- Smart word limits: ~15 words target, 20 max")
        print("- spaCy integration for enhanced keyword extraction")
        print("- Priority-based text combination preserving local context")
        print("- Normalized 0-1 timing values for segments")
        print("- Enhanced embedding quality for semantic search")
        print("- Robust handling of edge cases and special characters")
    else:
        print(f"\n⚠️  {total - passed} tests failed")
        print("Check output above for details")
    
    exit(0 if passed else 1)